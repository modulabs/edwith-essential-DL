# Edwith 논문으로 짚어보는 딥러닝의 맥

[모두의연구소](http://www.modulabs.co.kr) 풀잎스쿨 6기
[**edwith 논문으로 보는 딥러닝의 맥**](https://www.edwith.org/deeplearningchoi)을 보며 같이 공부하는 사람들이 정리한 repository 입니다.

이 자료들은 edwith 강의를 중심으로 해당 주제에 맞는 여러 참고 문헌들과 풀잎스쿨 발표자료를 정리한 것입니다.

* 전체 발표자들: 강성현, 강재호, 김경태, 김선호, 문동지, 이규희, 이일구, 조원양, 최성욱, 한상훈
* 퍼실이: 이일구


### 1주 (2019. 01. 12.)
* [4가지 CNN 살펴보기: AlexNet, VGG, GoogLeNet, ResNet](https://www.edwith.org/deeplearningchoi/lecture/15296/)
  * 발표자료
    * 강성현님: ResNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week01/Deep_Residual_Learning_강성현.pdf)
  * 강의에서 제안한 참고문헌
    * ImageNet Classification with Deep Convolutional Neural Networks [paper pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
    * Very deep convolutional networks for large-scale image recognition [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)
    * Going deeper with convolutions [https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)
    * Deep Residual Learning for Image Recognition [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * Densely Connected Convolutional Networks [https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)
    * 김성훈 교수님 DenseNet [PR12](https://www.youtube.com/watch?v=fe2Vn0mwALI&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=30&t=0s)
    * 유재준님 Inception and Xception [PR12](https://www.youtube.com/watch?v=V0dLhyg5_Dw&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=36&t=0s)


### 2주 (2019. 01. 19.)
* [Overfitting을 막는 regularization](https://www.edwith.org/deeplearningchoi/lecture/15299/)
  * 발표자료
    * 김경태님: 최성준님 발표자료 [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=22472&autoClose=true)
    * 한상훈님: Batch Normalization 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week02/Batch_Normalization_한상훈.pdf)
  * 강의에서 제안한 참고문헌
    * Dropout : A Simple Way to Prevent Neural Networks from Overfitting [paper pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)
    * Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift [https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * 정영재님 Batch Normalization [PR12](https://www.youtube.com/watch?v=TDx8iZHwFtM&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=23&t=0s)


### 3주 (2019. 01. 26.)
* [이미지의 각 픽셀을 분류하는 Semantic Segmentation](https://www.edwith.org/deeplearningchoi/lecture/15554/)
  * 발표자료
    * 문동지님: Fully Convolutional Networks for Semantic Segmentation 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week03/Fully_Convolutional_Network_문동지.pdf)
    * 김선호님: DeepLab 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week03/DeepLab_김선호.pdf)
    * 강재호님: UNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week03/UNet_강재호.pdf)
  * 강의에서 제안한 참고문헌
    * Fully Convolutional Networks for Semantic Segmentation [paper pdf](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf)
    * Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs [https://arxiv.org/abs/1412.7062](https://arxiv.org/abs/1412.7062)
    * Learning deconvolution network for semantic segmentation [https://arxiv.org/abs/1505.04366](https://arxiv.org/abs/1505.04366)
    * DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs [https://arxiv.org/abs/1606.00915](https://arxiv.org/abs/1606.00915)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * 김태오님 DeepLab [PR12](https://www.youtube.com/watch?v=JiC78rUF4iI&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=47&t=0s)


### 4주 (2019. 02. 09.)
* [Residual Networks가 왜 잘 되는지 해석해보기](https://www.edwith.org/deeplearningchoi/lecture/15566/)
  * 발표자료
    * 이규희님: Resnet v2 (Identity Mappings in Deep Residual Networks) 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week04/Identity_Mappings_ResNet_이규ᄒdf)
    * 최성욱님: Exponential Ensembles 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week04/ResNet_Ensemble_최성욱.pdf)
    * 조원양님: Wide ResNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week04/Wide_Residual_Networks_조원양.pdf)
  * 강의에서 제안한 참고문헌
    * Deep Residual Learning for Image Recognition [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)
    * Identity Mappings in Deep Residual Networks [https://arxiv.org/abs/1603.05027](https://arxiv.org/abs/1603.05027)
    * Residual Networks are Exponential Ensembles of Relatively Shallow Networks [https://arxiv.org/abs/1605.06431](https://arxiv.org/abs/1605.06431)
    * Wide Residual Networks [https://arxiv.org/abs/1605.07146](https://arxiv.org/abs/1605.07146)


### 5주 (2019. 02. 16.)
* [Image Detection 방법론: RCNN, SPPNet, FastRCNN, FasterRCNN](https://www.edwith.org/deeplearningchoi/lecture/15568/)
  * 발표자료
    * 이일구님: R-CNN, SPPNet (최성준님 팔표자료 이용) [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=22946&autoClose=true)
    * 강성현님: Fast R-CNN, Faster R-CNN 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week05/FasterRCNN_강성현.pdf)
  * 강의에서 제안한 참고문헌
    * Rich feature hierarchies for accurate object detection and semantic segmentation [https://arxiv.org/abs/1311.2524](https://arxiv.org/abs/1311.2524)
    * Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition [https://arxiv.org/abs/1406.4729](https://arxiv.org/abs/1406.4729)
    * Fast R-CNN [https://arxiv.org/abs/1504.08083](https://arxiv.org/abs/1504.08083)
    * Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks [https://arxiv.org/abs/1506.01497](https://arxiv.org/abs/1506.01497)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * Oxford Visual Geometry Groups: Detection 자료 [detection-part1.pdf](http://aims.robots.ox.ac.uk/wp-content/uploads/2018/01/detection-part1.pdf?fbclid=IwAR3rtpbi65pY02xF98jrqW6PtrhSLgCrdeVJUc6H05Fp50nG5D9RUsvwPQE),
      [detection-part2.pdf](http://aims.robots.ox.ac.uk/wp-content/uploads/2018/01/detection-part2.pdf?fbclid=IwAR14fW3qRdmI3kiaM_O5CZo8ayApCnqe84YPeqcnk1xP0Oet-w20luMZqRo)
    * 이호성님 detection 정리 [github](https://github.com/hoya012/deep_learning_object_detection)
    * 김화평님 Faster R-CNN [slideshare](https://www.slideshare.net/hpkim0512/tutorial-of-faster-rcnn)
    * 박진우님 Faster R-CNN [blog](https://curt-park.github.io/2017-03-17/faster-rcnn/?fbclid=IwAR04YURbBkWJ5oJEquDmpjhTeG1SYHs5S4ZfsXXYkaxR5tnQuwWa_88R9-o)
    * 이진원님 Faster R-CNN [PR12](https://www.youtube.com/watch?v=kcPAGIgBGRs)


### 6주 (2019. 02. 23.)
* [Image Detection 방법론: AttentionNet, SSD, YOLO YOLOv2](https://www.edwith.org/deeplearningchoi/lecture/15579/)
  * 발표자료
    * 문동지님: SSD, YOLO 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week06/yolo_ssd_문동지.pdf)
    * 조원양님: RetinaNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week06/FocalLossforDenseObjectDetectionReview_조원양.pdf)
  * 강의에서 제안한 참고문헌
    * AttentionNet: Aggregating Weak Directions for Accurate Object Detection [https://arxiv.org/abs/1506.07704](https://arxiv.org/abs/1506.07704)
    * You Only Look Once: Unified, Real-Time Object Detection [https://arxiv.org/abs/1506.02640](https://arxiv.org/abs/1506.02640)
    * YOLO9000: Better, Faster, Stronger [https://arxiv.org/abs/1612.08242](https://arxiv.org/abs/1612.08242)
    * SSD: Single Shot MultiBox Detector [https://arxiv.org/abs/1512.02325](https://arxiv.org/abs/1512.02325)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * 박진우님 YOLO [blog](https://curt-park.github.io/2017-03-26/yolo/)
    * 이진원님 YOLO9000 [PR12](https://www.youtube.com/watch?v=6fdclSGgeio&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=25&t=0s)
    * YOLOv3: An Incremental Improvement [https://arxiv.org/abs/1804.02767](https://arxiv.org/abs/1804.02767)
    * 김태오님 Mask R-CNN [PR12](https://www.youtube.com/watch?v=RtSZALC9DlU&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=59&t=0s)


### 7주 (2019. 03. 02.) 
* 징검다리 휴일 (공부도 쉬는게 중요합니다)


### 8주 (2019. 03. 09.) 
* [이미지와 질문이 주어졌을 때 답을 맞추는 Visual QnA](https://www.edwith.org/deeplearningchoi/lecture/15580/)
  * 발표자료
    * 이일구님: DPPNet (최성준님 발표자료 이용) [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=22956&autoClose=true)
    * 한상훈님: Multimodal Compact Bilinear Pooling 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week08/Multimodal_Compact_Bilinear_Pooling_한ᄉ.pdf)
  * 강의에서 제안한 참고문헌
    * Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction [https://arxiv.org/abs/1511.05756](https://arxiv.org/abs/1511.05756)
    * Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding [https://arxiv.org/abs/1606.01847](https://arxiv.org/abs/1606.01847)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * DPPNet 논문에 나온 `Wu-Palmer` similarity [youbute](https://www.youtube.com/watch?v=2sQp7jJJmeg)
