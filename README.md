# Edwith 논문으로 짚어보는 딥러닝의 맥

[모두의연구소](http://www.modulabs.co.kr) 풀잎스쿨 6기
[**edwith 논문으로 보는 딥러닝의 맥**](https://www.edwith.org/deeplearningchoi)을 보며 같이 공부하는 사람들이 정리한 repository 입니다.

이 자료들은 edwith 강의를 중심으로 해당 주제에 맞는 여러 참고 문헌들과 풀잎스쿨 발표자료를 정리한 것입니다.

* 전체 발표자들: 강성현, 강재호, 김경태, 김선호, 문동지, 이규희, 이일구, 조원양, 최성욱, 한상훈
* 퍼실이: 이일구


### 1주 (2019. 01. 12.)
* [4가지 CNN 살펴보기: AlexNet, VGG, GoogLeNet, ResNet](https://www.edwith.org/deeplearningchoi/lecture/15296/)
  * 발표자료
    * 강성현님: ResNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week01/Deep_Residual_Learning_강성현.pdf)
  * 강의에서 제안한 참고문헌
    * ImageNet Classification with Deep Convolutional Neural Networks [paper pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
    * Very deep convolutional networks for large-scale image recognition [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)
    * Going deeper with convolutions [https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)
    * Deep Residual Learning for Image Recognition [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * Densely Connected Convolutional Networks [https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)
    * 김성훈 교수님 DenseNet [PR12](https://www.youtube.com/watch?v=fe2Vn0mwALI&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=30&t=0s)
    * 유재준님 Inception and Xception [PR12](https://www.youtube.com/watch?v=V0dLhyg5_Dw&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=36&t=0s)


### 2주 (2019. 01. 19.)
* [Overfitting을 막는 regularization](https://www.edwith.org/deeplearningchoi/lecture/15299/)
  * 발표자료
    * 김경태님: 최성준님 발표자료 [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=22472&autoClose=true)
    * 한상훈님: Batch Normalization 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week02/Batch_Normalization_한상훈.pdf)
  * 강의에서 제안한 참고문헌
    * Dropout : A Simple Way to Prevent Neural Networks from Overfitting [paper pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)
    * Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift [https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * 정영재님 Batch Normalization [PR12](https://www.youtube.com/watch?v=TDx8iZHwFtM&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=23&t=0s)


### 3주 (2019. 01. 26.)
* [이미지의 각 픽셀을 분류하는 Semantic Segmentation](https://www.edwith.org/deeplearningchoi/lecture/15554/)
  * 발표자료
    * 문동지님: Fully Convolutional Networks for Semantic Segmentation 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week03/Fully_Convolutional_Network_문동지.pdf)
    * 김선호님: DeepLab 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week03/DeepLab_김선호.pdf)
    * 강재호님: UNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week03/UNet_강재호.pdf)
  * 강의에서 제안한 참고문헌
    * Fully Convolutional Networks for Semantic Segmentation [paper pdf](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf)
    * Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs [https://arxiv.org/abs/1412.7062](https://arxiv.org/abs/1412.7062)
    * Learning deconvolution network for semantic segmentation [https://arxiv.org/abs/1505.04366](https://arxiv.org/abs/1505.04366)
    * DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs [https://arxiv.org/abs/1606.00915](https://arxiv.org/abs/1606.00915)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * 김태오님 DeepLab [PR12](https://www.youtube.com/watch?v=JiC78rUF4iI&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=47&t=0s)


### 4주 (2019. 02. 09.)
* [Residual Networks가 왜 잘 되는지 해석해보기](https://www.edwith.org/deeplearningchoi/lecture/15566/)
  * 발표자료
    * 이규희님: Resnet v2 (Identity Mappings in Deep Residual Networks) 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week04/Identity_Mappings_ResNet_이규희.pdf)
    * 최성욱님: Exponential Ensembles 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week04/ResNet_Ensemble_최성욱.pdf)
    * 조원양님: Wide ResNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week04/Wide_Residual_Networks_조원양.pdf)
  * 강의에서 제안한 참고문헌
    * Deep Residual Learning for Image Recognition [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)
    * Identity Mappings in Deep Residual Networks [https://arxiv.org/abs/1603.05027](https://arxiv.org/abs/1603.05027)
    * Residual Networks are Exponential Ensembles of Relatively Shallow Networks [https://arxiv.org/abs/1605.06431](https://arxiv.org/abs/1605.06431)
    * Wide Residual Networks [https://arxiv.org/abs/1605.07146](https://arxiv.org/abs/1605.07146)


### 5주 (2019. 02. 16.)
* [Image Detection 방법론: RCNN, SPPNet, FastRCNN, FasterRCNN](https://www.edwith.org/deeplearningchoi/lecture/15568/)
  * 발표자료
    * 이일구님: R-CNN, SPPNet (최성준님 팔표자료 이용) [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=22946&autoClose=true)
    * 강성현님: Fast R-CNN, Faster R-CNN 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week05/FasterRCNN_강성현.pdf)
  * 강의에서 제안한 참고문헌
    * Rich feature hierarchies for accurate object detection and semantic segmentation [https://arxiv.org/abs/1311.2524](https://arxiv.org/abs/1311.2524)
    * Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition [https://arxiv.org/abs/1406.4729](https://arxiv.org/abs/1406.4729)
    * Fast R-CNN [https://arxiv.org/abs/1504.08083](https://arxiv.org/abs/1504.08083)
    * Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks [https://arxiv.org/abs/1506.01497](https://arxiv.org/abs/1506.01497)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * Oxford Visual Geometry Groups: Detection 자료 [detection-part1.pdf](http://aims.robots.ox.ac.uk/wp-content/uploads/2018/01/detection-part1.pdf?fbclid=IwAR3rtpbi65pY02xF98jrqW6PtrhSLgCrdeVJUc6H05Fp50nG5D9RUsvwPQE),
      [detection-part2.pdf](http://aims.robots.ox.ac.uk/wp-content/uploads/2018/01/detection-part2.pdf?fbclid=IwAR14fW3qRdmI3kiaM_O5CZo8ayApCnqe84YPeqcnk1xP0Oet-w20luMZqRo)
    * 이호성님 detection 정리 [github](https://github.com/hoya012/deep_learning_object_detection)
    * 김화평님 Faster R-CNN [slideshare](https://www.slideshare.net/hpkim0512/tutorial-of-faster-rcnn)
    * 박진우님 Faster R-CNN [blog](https://curt-park.github.io/2017-03-17/faster-rcnn/?fbclid=IwAR04YURbBkWJ5oJEquDmpjhTeG1SYHs5S4ZfsXXYkaxR5tnQuwWa_88R9-o)
    * 이진원님 Faster R-CNN [PR12](https://www.youtube.com/watch?v=kcPAGIgBGRs)


### 6주 (2019. 02. 23.)
* [Image Detection 방법론: AttentionNet, SSD, YOLO YOLOv2](https://www.edwith.org/deeplearningchoi/lecture/15579/)
  * 발표자료
    * 문동지님: SSD, YOLO 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week06/yolo_ssd_문동지.pdf)
    * 조원양님: RetinaNet 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week06/FocalLossforDenseObjectDetectionReview_조원양.pdf)
  * 강의에서 제안한 참고문헌
    * AttentionNet: Aggregating Weak Directions for Accurate Object Detection [https://arxiv.org/abs/1506.07704](https://arxiv.org/abs/1506.07704)
    * You Only Look Once: Unified, Real-Time Object Detection [https://arxiv.org/abs/1506.02640](https://arxiv.org/abs/1506.02640)
    * YOLO9000: Better, Faster, Stronger [https://arxiv.org/abs/1612.08242](https://arxiv.org/abs/1612.08242)
    * SSD: Single Shot MultiBox Detector [https://arxiv.org/abs/1512.02325](https://arxiv.org/abs/1512.02325)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * 박진우님 YOLO [blog](https://curt-park.github.io/2017-03-26/yolo/)
    * 이진원님 YOLO9000 [PR12](https://www.youtube.com/watch?v=6fdclSGgeio&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=25&t=0s)
    * YOLOv3: An Incremental Improvement [https://arxiv.org/abs/1804.02767](https://arxiv.org/abs/1804.02767)
    * 김태오님 Mask R-CNN [PR12](https://www.youtube.com/watch?v=RtSZALC9DlU&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS&index=59&t=0s)


### 7주 (2019. 03. 02.) 
* 징검다리 휴일 (공부도 쉬는게 중요합니다)


### 8주 (2019. 03. 09.) 
* [이미지와 질문이 주어졌을 때 답을 맞추는 Visual QnA](https://www.edwith.org/deeplearningchoi/lecture/15580/)
  * 발표자료
    * 이일구님: DPPNet (최성준님 발표자료 이용) [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=22956&autoClose=true)
    * 한상훈님: Multimodal Compact Bilinear Pooling 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week08/Multimodal_Compact_Bilinear_Pooling_한상훈.pdf)
  * 강의에서 제안한 참고문헌
    * Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction [https://arxiv.org/abs/1511.05756](https://arxiv.org/abs/1511.05756)
    * Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding [https://arxiv.org/abs/1606.01847](https://arxiv.org/abs/1606.01847)
  * 더 보면 좋을 참고문헌 (블로그 등)
    * DPPNet 논문에 나온 `Wu-Palmer` similarity [youbute](https://www.youtube.com/watch?v=2sQp7jJJmeg)


### 9주 (2019. 03. 16.) 
* [이미지를 설명하는 문장을 만들어내는 Image Captioning](https://www.edwith.org/deeplearningchoi/lecture/15583/)
  * 발표자료
    * 강재호님: Show and Tell / Show, Attend and Tell (최성준님 발표자료 이용) [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=22960&autoClose=true)
    * 이규희님: DenseCap: Fully Convolutional Localization Networks for Dense Captioning 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week09/DenseCap_이규희.pdf)
  * 강의에서 제안한 참고문헌
    * Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge
      * [IEEE Transactions on Pattern Analysis and Machine Intelligence (Volume: 39 , Issue: 4 , April 1 2017)](https://ieeexplore.ieee.org/document/7505636?arnumber=7505636)
      * [https://arxiv.org/abs/1411.4555](https://arxiv.org/abs/1411.4555)
    * Show, Attend and Tell: Neural Image Caption Generation with Visual Attention [https://arxiv.org/abs/1502.03044](https://arxiv.org/abs/1502.03044)
    * DenseCap: Fully Convolutional Localization Networks for Dense Captioning
      * [Demo site](https://cs.stanford.edu/people/karpathy/densecap/)
      * [https://arxiv.org/abs/1511.07571](https://arxiv.org/abs/1511.07571)
  * 더 보면 좋을 참고문헌 (github, 블로그 등)
    * Show and Tell TensorFlow official code [TensorFlow models](https://github.com/tensorflow/models/tree/master/research/im2txt)
    * Show, Attend and Tell TensorFlow official code [TensorFlow Tutorials](https://www.tensorflow.org/alpha/tutorials/sequences/image_captioning)
    * DenseCap: Fully Convolutional Localization Networks for Dense Captioning [author official code](https://github.com/jcjohnson/densecap)
    * 강지양님 Show and Tell [PR12](https://www.youtube.com/watch?v=BrmCnoYhQb4)


### 10주 (2019. 03. 23.) 
* [주어진 사진을 원하는 화풍으로 만드는 Neural Style](https://www.edwith.org/deeplearningchoi/lecture/15849/)
  * 발표자료
    * 문동지님: A Neural Algorithm of Artistic Style (최성준님 발표자료 이용) [pptx link](https://www.edwith.org/downloadFile/fileDownload?attachmentId=23336&autoClose=true)
    * 한상훈님: Perceptual losses for style transfer and super-resolution 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week10/Perceptual_losses_한상훈.pdf)
    * 조원양님: Deep Photo Style Transfer 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week10/Deep_Photo_Style_Transfer_조원양.pdf)
  * 강의에서 제안한 참고문헌
    * Texture Synthesis Using Convolutional Neural Networks 
      * [paper link](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjcgKzlpszhAhULc3AKHR-6B8gQFjAAegQIARAC&url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5633-texture-synthesis-using-convolutional-neural-networks.pdf&usg=AOvVaw07fwBeQRsNiAusjlPH9dve)
      * [https://arxiv.org/abs/1505.07376](https://arxiv.org/abs/1505.07376)
  * 더 보면 좋을 참고문헌 (github, 블로그 등)
    * Neural Style Transfer TensorFlow official code [TensorFlow Tutorials](https://github.com/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb)
    * 김승일 소장님 Deep Photo Style Transfer [PR12](https://www.youtube.com/watch?v=YF6nLVDlznE&list=PLWKf9beHi3Tg50UoyTe6rIm20sVQOH1br&index=8)


### 11주 (2019. 03. 30.) 
* [Generative Adversarial Network](https://www.edwith.org/deeplearningchoi/lecture/15846/)
  * 발표자료
    * 김선호님: GAN, DCGAN, Pix2Pix, CycleGAN 발표자료 [pdf link](https://github.com/modulabs/edwith-essential-DL/blob/master/week11/)
  * 강의에서 제안한 참고문헌
    * Generative Adversarial Network [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)
    * Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks [https://arxiv.org/abs/1511.06434](https://arxiv.org/abs/1511.06434)
    * Generative Adversarial Text to Image Synthesis [https://arxiv.org/abs/1605.05396](https://arxiv.org/abs/1605.05396)
  * 더 보면 좋을 참고문헌 (github, 블로그 등)
    * NIPS 2016 Tutorial: Generative Adversarial Networks [https://arxiv.org/abs/1701.00160](https://arxiv.org/abs/1701.00160)
    * Generative Adversarial Networks : An Overview [https://arxiv.org/abs/1710.07035](https://arxiv.org/abs/1710.07035)
    * DCGAN TensorFlow official code [TensorFlow Tutorials](https://www.tensorflow.org/alpha/tutorials/generative/dcgan)
    * Pix2Pix TensorFlow official code [TensorFlow Tutorials](https://www.tensorflow.org/alpha/tutorials/generative/pix2pix)
    * 이일구님 Generative models tensorflow version 2.0 style collection [github](https://github.com/ilguyi/generative.models.tensorflow.v2)
    * 이활석님 tensorflow-generative-model-collections [github](https://github.com/hwalsuklee/tensorflow-generative-model-collections)
    * 유재준님 GAN [PR12](https://www.youtube.com/watch?v=L3hz57whyNw&list=PLWKf9beHi3Tg50UoyTe6rIm20sVQOH1br&index=2)
    * 김승일 소장님 GAN [PR12](https://www.youtube.com/watch?v=iCgT8G4PkqI&list=PLWKf9beHi3Tg50UoyTe6rIm20sVQOH1br&index=52)
    * 차준범님 InfoGAN [PR12](https://www.youtube.com/watch?v=_4jbgniqt_Q&list=PLWKf9beHi3Tg50UoyTe6rIm20sVQOH1br&index=19)























